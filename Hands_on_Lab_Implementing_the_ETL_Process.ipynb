{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Hands-on Lab: Implementing the ETL (Extract, Transform, Load) Process**"
      ],
      "metadata": {
        "id": "MwRtqhfoEmJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "\n",
        "In this hands-on lab, students will learn how to implement the fundamental steps of the ETL process by extracting data from multiple sources, transforming the data, and loading it into a database. Students will use Python along with libraries such as Pandas for data transformation and PyMongo for loading the data into a MongoDB database.\n",
        "\n",
        "By the end of this lab, students will be able to:\n",
        "\n",
        "* Extract data from different sources (CSV and API).\n",
        "* Clean, transform, and validate the data.\n",
        "* Load the transformed data into MongoDB.\n",
        "* Automate the ETL process by building a reusable pipeline."
      ],
      "metadata": {
        "id": "_flGWYZjEygA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-requisites:**\n",
        "\n",
        "* Basic knowledge of Python.\n",
        "* MongoDB Atlas account (or a local MongoDB instance).\n",
        "* Install the required Python libraries:\n",
        "\n"
      ],
      "metadata": {
        "id": "WNqvAT4rFKjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this Lab:**\n",
        "\n",
        "You are tasked with creating an ETL pipeline for a fictitious retail company. You will extract product and sales data from different sources (a CSV file and a REST API), transform the data by cleaning and standardizing it, and load the transformed data into MongoDB for further analysis."
      ],
      "metadata": {
        "id": "Af48YJb-FwIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Extract Data**\n",
        "\n",
        "**1.1. Extract Product Data from a CSV File**\n",
        "\n",
        "Create a CSV file named ***products.csv*** with the following data:\n",
        "\n",
        "product_id,product_name,category,price\n",
        "\n",
        "1001,Laptop,Electronics,1200\n",
        "\n",
        "1002,Smartphone,Electronics,800\n",
        "\n",
        "1003,Chair,Furniture,150"
      ],
      "metadata": {
        "id": "HdEXdoqcF4wf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Python and Pandas to extract the product data from this CSV file."
      ],
      "metadata": {
        "id": "3C7Wvw-WGM9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Extract data from the CSV file\n",
        "products_df = pd.read_csv('products.csv')\n",
        "print(\"Extracted Product Data:\")\n",
        "print(products_df)\n"
      ],
      "metadata": {
        "id": "1e-U7ChnGOSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2. Extract Sales Data from a REST API**\n",
        "\n",
        "For the sales data, we will simulate an API response using a dictionary. In a real-world scenario, you would use the requests library to fetch data from an API."
      ],
      "metadata": {
        "id": "ftylwwhwGRT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Simulated API response (in a real scenario, use requests.get(URL).json())\n",
        "sales_data = [\n",
        "    {\"sale_id\": \"S001\", \"product_id\": \"1001\", \"quantity\": 2, \"total\": 2400},\n",
        "    {\"sale_id\": \"S002\", \"product_id\": \"1002\", \"quantity\": 1, \"total\": 800},\n",
        "    {\"sale_id\": \"S003\", \"product_id\": \"1003\", \"quantity\": 4, \"total\": 600}\n",
        "]\n",
        "\n",
        "print(\"Extracted Sales Data:\")\n",
        "print(sales_data)\n"
      ],
      "metadata": {
        "id": "mcwhIOGxGXok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Transform Data**\n",
        "\n",
        "**2.1. Clean and Standardize the Product Data**\n",
        "\n",
        "Use Pandas to clean and transform the product data. For this example, let's assume you need to ensure the price field is numeric and filter out products that are too expensive."
      ],
      "metadata": {
        "id": "QARgvzg4Gaem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sales_data to a DataFrame\n",
        "sales_df = pd.DataFrame(sales_data)\n",
        "\n",
        "# Join sales data with product data to add product_name\n",
        "sales_df = pd.merge(sales_df, products_df[['product_id', 'product_name']], on='product_id', how='left')\n",
        "print(\"Enriched Sales Data:\")\n",
        "print(sales_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "bPQrKmOTGf8M",
        "outputId": "b085b850-37e2-4daf-c20a-25c0a7205057"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b875b6423d0b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert sales_data to a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msales_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Join sales data with product data to add product_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msales_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproducts_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'product_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2. Enrich the Sales Data**\n",
        "\n",
        "For the sales data, we'll perform a simple enrichment by adding the product_name to each sale by joining the sales_data and products_df on the product_id."
      ],
      "metadata": {
        "id": "XWTlr7q-GiMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sales_data to a DataFrame\n",
        "sales_df = pd.DataFrame(sales_data)\n",
        "\n",
        "# Join sales data with product data to add product_name\n",
        "sales_df = pd.merge(sales_df, products_df[['product_id', 'product_name']], on='product_id', how='left')\n",
        "print(\"Enriched Sales Data:\")\n",
        "print(sales_df)\n"
      ],
      "metadata": {
        "id": "-AE458wsGniG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Load Data into MongoDB**\n",
        "\n",
        "Now that the data is transformed and cleaned, load the product and sales data into MongoDB.\n",
        "\n",
        "**3.1. Connect to MongoDB**\n",
        "\n",
        "Ensure you have MongoDB running locally or use MongoDB Atlas. Connect to MongoDB using PyMongo."
      ],
      "metadata": {
        "id": "N_J9biezGzQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "# Connect to MongoDB (replace <username> and <password> with your MongoDB Atlas credentials)\n",
        "client = MongoClient(\"mongodb+srv://<username>:<password>@cluster0.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\")\n",
        "db = client['retail_db']\n"
      ],
      "metadata": {
        "id": "J-WpayvQG3NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2. Load Product Data**\n",
        "\n",
        "Insert the transformed product data into the MongoDB products collection."
      ],
      "metadata": {
        "id": "KdbvO_ynG5W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to dictionary and insert into MongoDB\n",
        "product_records = filtered_products_df.to_dict(orient='records')\n",
        "db.products.insert_many(product_records)\n",
        "print(\"Loaded Product Data into MongoDB\")\n"
      ],
      "metadata": {
        "id": "yFPviZ0jG-hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3. Load Sales Data**\n",
        "\n",
        "Insert the enriched sales data into the MongoDB sales collection."
      ],
      "metadata": {
        "id": "RcPF_GfEHBcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to dictionary and insert into MongoDB\n",
        "sales_records = sales_df.to_dict(orient='records')\n",
        "db.sales.insert_many(sales_records)\n",
        "print(\"Loaded Sales Data into MongoDB\")\n"
      ],
      "metadata": {
        "id": "xGqJWM2sHHSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Automate the ETL Process**\n",
        "\n",
        "To make the ETL process reusable, wrap the steps into functions and run the ETL pipeline from start to finish."
      ],
      "metadata": {
        "id": "0w-Iu3KuHKGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_products():\n",
        "    return pd.read_csv('products.csv')\n",
        "\n",
        "def extract_sales():\n",
        "    return pd.DataFrame(sales_data)\n",
        "\n",
        "def transform_products(products_df):\n",
        "    products_df['price'] = pd.to_numeric(products_df['price'], errors='coerce')\n",
        "    return products_df[products_df['price'] < 1000]\n",
        "\n",
        "def transform_sales(sales_df, products_df):\n",
        "    return pd.merge(sales_df, products_df[['product_id', 'product_name']], on='product_id', how='left')\n",
        "\n",
        "def load_data(products_df, sales_df):\n",
        "    db.products.insert_many(products_df.to_dict(orient='records'))\n",
        "    db.sales.insert_many(sales_df.to_dict(orient='records'))\n",
        "\n",
        "# Run the ETL pipeline\n",
        "products_df = extract_products()\n",
        "sales_df = extract_sales()\n",
        "transformed_products_df = transform_products(products_df)\n",
        "transformed_sales_df = transform_sales(sales_df, products_df)\n",
        "load_data(transformed_products_df, transformed_sales_df)\n",
        "print(\"ETL Process Completed!\")\n"
      ],
      "metadata": {
        "id": "p-h6IeqiHRIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "This hands-on lab provides a comprehensive introduction to the ETL process, from extracting raw data from multiple sources, transforming it for quality and consistency, and finally loading it into MongoDB."
      ],
      "metadata": {
        "id": "IJ2xNTfeEjAk"
      }
    }
  ]
}